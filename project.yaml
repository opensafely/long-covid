version: '3.0'

expectations:
  population_size: 2000

actions:

  generate_cohort:
    run: cohortextractor:latest generate_cohort --study-definition study_definition_cohort
    outputs:
      highly_sensitive:
        cohort: output/input_cohort.csv

  count_by_strata:
    run: python:latest python analysis/all_time_counts.py
    needs: [generate_cohort]
    outputs:
      moderately_sensitive:
        table: output/counts_table.csv
        practice_distribution: output/practice_distribution.csv
        per_week: output/code_use_per_week_long_covid.csv
        per_week_pvf: output/code_use_per_week_post_viral_fatigue.csv
        code_table: output/all_long_covid_codes.csv
        practice_summ: output/practice_summ.txt

  # # to be run locally
  generate_report_notebook:
      run: jupyter:latest jupyter nbconvert /workspace/analysis/long_covid_coding_report.ipynb --execute --to html --output-dir=/workspace/released_outputs --ExecutePreprocessor.timeout=86400 --no-input
      outputs:
        moderately_sensitive:
          notebook: released_outputs/long_covid_coding_report.html

  generate_cohort_v2:
    run: cohortextractor-v2:latest --cohort-definition analysis/study_definition_v2.py --output output/input_cohort_v2.csv --dummy-data-file analysis/dummy_data.csv
    outputs:
      highly_sensitive:
        cohort: output/input_cohort_v2.csv

  count_by_strata_v2:
    run: python:latest python analysis/all_time_counts_v2.py
    needs: [generate_cohort_v2]
    outputs:
      moderately_sensitive:
        table: output/counts_table_v2.csv
        practice_distribution: output/practice_distribution_v2.csv
        per_week: output/code_use_per_week_long_covid_v2.csv
        per_week_pvf: output/code_use_per_week_post_viral_fatigue_v2.csv
        code_table: output/all_long_covid_codes_v2.csv
        practice_summ: output/practice_summ_v2.txt
